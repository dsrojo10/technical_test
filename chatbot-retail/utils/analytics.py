import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import sqlite3
from pathlib import Path
import config
from collections import Counter
import re

class AnalyticsManager:
    """Manejo de analytics y estad√≠sticas del chatbot"""
    
    def __init__(self):
        self.db_path = config.DATABASE_PATH
    
    def get_conversation_stats(self, days=30):
        """Obtiene estad√≠sticas de conversaciones"""
        with sqlite3.connect(self.db_path) as conn:
            # Conversaciones por d√≠a
            query_daily = """
                SELECT DATE(timestamp) as fecha, COUNT(*) as total_conversaciones
                FROM conversaciones 
                WHERE timestamp >= datetime('now', '-{} days')
                GROUP BY DATE(timestamp)
                ORDER BY fecha
            """.format(days)
            
            df_daily = pd.read_sql_query(query_daily, conn)
            
            # Tipos de consulta m√°s frecuentes
            query_types = """
                SELECT tipo_consulta, COUNT(*) as total
                FROM conversaciones 
                WHERE timestamp >= datetime('now', '-{} days')
                AND tipo_consulta IS NOT NULL
                GROUP BY tipo_consulta
                ORDER BY total DESC
            """.format(days)
            
            df_types = pd.read_sql_query(query_types, conn)
            
            # Usuarios m√°s activos
            query_users = """
                SELECT u.nombre_completo, COUNT(c.id) as total_mensajes
                FROM usuarios u
                JOIN conversaciones c ON u.id = c.usuario_id
                WHERE c.timestamp >= datetime('now', '-{} days')
                GROUP BY u.id, u.nombre_completo
                ORDER BY total_mensajes DESC
                LIMIT 10
            """.format(days)
            
            df_users = pd.read_sql_query(query_users, conn)
            
            return df_daily, df_types, df_users
    
    def get_word_frequency(self, days=30, limit=20):
        """Analiza frecuencia de palabras en mensajes de usuarios"""
        with sqlite3.connect(self.db_path) as conn:
            query = """
                SELECT mensaje_usuario
                FROM conversaciones 
                WHERE timestamp >= datetime('now', '-{} days')
            """.format(days)
            
            df = pd.read_sql_query(query, conn)
            
            # Procesar texto
            all_text = ' '.join(df['mensaje_usuario'].astype(str))
            
            # Limpiar y tokenizar
            words = re.findall(r'\b[a-z√°√©√≠√≥√∫√±√º]{3,}\b', all_text.lower())
            
            # Filtrar palabras comunes
            stop_words = {'que', 'para', 'con', 'una', 'por', 'del', 'las', 'los', 
                         'est√°', 'son', 'como', 'm√°s', 'pero', 'sus', 'sus', 'uno',
                         'sobre', 'todo', 'tambi√©n', 'despu√©s', 'hasta', 'otro',
                         'cuando', 'muy', 'sin', 'entre', 'ser', 'hay', 'donde',
                         'hola', 'gracias', 'buenos', 'd√≠as', 'buenas', 'tardes'}
            
            filtered_words = [w for w in words if w not in stop_words and len(w) > 3]
            
            # Contar frecuencias
            word_freq = Counter(filtered_words).most_common(limit)
            
            return pd.DataFrame(word_freq, columns=['palabra', 'frecuencia'])
    
    def get_hourly_distribution(self, days=30):
        """Obtiene distribuci√≥n de conversaciones por hora"""
        with sqlite3.connect(self.db_path) as conn:
            query = """
                SELECT 
                    CAST(strftime('%H', timestamp) AS INTEGER) as hora,
                    COUNT(*) as total_conversaciones
                FROM conversaciones 
                WHERE timestamp >= datetime('now', '-{} days')
                GROUP BY hora
                ORDER BY hora
            """.format(days)
            
            return pd.read_sql_query(query, conn)
    
    def get_user_engagement_metrics(self):
        """Obtiene m√©tricas de engagement de usuarios"""
        with sqlite3.connect(self.db_path) as conn:
            # Usuarios registrados vs an√≥nimos
            query_registration = """
                SELECT 
                    CASE 
                        WHEN usuario_id IS NULL THEN 'An√≥nimo'
                        ELSE 'Registrado'
                    END as tipo_usuario,
                    COUNT(*) as total_conversaciones
                FROM conversaciones
                GROUP BY tipo_usuario
            """
            
            df_registration = pd.read_sql_query(query_registration, conn)
            
            # Promedio de mensajes por usuario
            query_avg = """
                SELECT AVG(mensajes_por_usuario) as promedio_mensajes
                FROM (
                    SELECT COUNT(*) as mensajes_por_usuario
                    FROM conversaciones
                    WHERE usuario_id IS NOT NULL
                    GROUP BY usuario_id
                )
            """
            
            avg_result = pd.read_sql_query(query_avg, conn)
            avg_messages = avg_result['promedio_mensajes'].iloc[0] if not avg_result.empty else 0
            
            return df_registration, avg_messages
    
    def render_analytics_dashboard(self):
        """Renderiza el dashboard completo de analytics"""
        st.markdown("# üìä Analytics Dashboard")
        st.markdown("---")
        
        # Sidebar para filtros
        with st.sidebar:
            st.markdown("### üîß Filtros")
            days_filter = st.selectbox(
                "Per√≠odo de an√°lisis",
                [7, 15, 30, 60, 90],
                index=2,
                help="Selecciona el n√∫mero de d√≠as para el an√°lisis"
            )
            
            st.markdown("### üìà M√©tricas Generales")
            
            # M√©tricas r√°pidas
            with sqlite3.connect(self.db_path) as conn:
                # Total conversaciones
                total_conv = pd.read_sql_query(
                    f"SELECT COUNT(*) as total FROM conversaciones WHERE timestamp >= datetime('now', '-{days_filter} days')",
                    conn
                )['total'].iloc[0]
                
                # Total usuarios √∫nicos
                total_users = pd.read_sql_query(
                    f"SELECT COUNT(DISTINCT usuario_id) as total FROM conversaciones WHERE timestamp >= datetime('now', '-{days_filter} days') AND usuario_id IS NOT NULL",
                    conn
                )['total'].iloc[0]
                
                # Promedio diario
                avg_daily = total_conv / days_filter if days_filter > 0 else 0
            
            st.metric("Conversaciones", total_conv)
            st.metric("Usuarios √önicos", total_users)
            st.metric("Promedio Diario", f"{avg_daily:.1f}")
        
        # Tabs principales
        tab1, tab2, tab3, tab4 = st.tabs(["üìà Tendencias", "üí¨ Conversaciones", "üë• Usuarios", "üîç Palabras Clave"])
        
        with tab1:
            self._render_trends_tab(days_filter)
        
        with tab2:
            self._render_conversations_tab(days_filter)
        
        with tab3:
            self._render_users_tab(days_filter)
        
        with tab4:
            self._render_words_tab(days_filter)
    
    def _render_trends_tab(self, days):
        """Renderiza la pesta√±a de tendencias"""
        st.markdown("## üìà Tendencias de Uso")
        
        # Obtener datos
        df_daily, df_types, df_users = self.get_conversation_stats(days)
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Gr√°fico de conversaciones por d√≠a
            if not df_daily.empty:
                fig_daily = px.line(
                    df_daily, 
                    x='fecha', 
                    y='total_conversaciones',
                    title='Conversaciones por D√≠a',
                    markers=True
                )
                fig_daily.update_layout(
                    xaxis_title="Fecha",
                    yaxis_title="N√∫mero de Conversaciones"
                )
                st.plotly_chart(fig_daily, use_container_width=True)
            else:
                st.info("No hay datos suficientes para mostrar tendencias diarias")
        
        with col2:
            # Distribuci√≥n por horas
            df_hourly = self.get_hourly_distribution(days)
            if not df_hourly.empty:
                fig_hourly = px.bar(
                    df_hourly,
                    x='hora',
                    y='total_conversaciones',
                    title='Distribuci√≥n de Conversaciones por Hora'
                )
                fig_hourly.update_layout(
                    xaxis_title="Hora del D√≠a",
                    yaxis_title="N√∫mero de Conversaciones"
                )
                st.plotly_chart(fig_hourly, use_container_width=True)
            else:
                st.info("No hay datos suficientes para mostrar distribuci√≥n horaria")
    
    def _render_conversations_tab(self, days):
        """Renderiza la pesta√±a de an√°lisis de conversaciones"""
        st.markdown("## üí¨ An√°lisis de Conversaciones")
        
        df_daily, df_types, df_users = self.get_conversation_stats(days)
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Tipos de consulta
            if not df_types.empty:
                fig_types = px.pie(
                    df_types,
                    values='total',
                    names='tipo_consulta',
                    title='Distribuci√≥n de Tipos de Consulta'
                )
                st.plotly_chart(fig_types, use_container_width=True)
            else:
                st.info("No hay datos de tipos de consulta")
        
        with col2:
            # Engagement metrics
            df_registration, avg_messages = self.get_user_engagement_metrics()
            if not df_registration.empty:
                fig_engagement = px.bar(
                    df_registration,
                    x='tipo_usuario',
                    y='total_conversaciones',
                    title='Usuarios Registrados vs An√≥nimos',
                    color='tipo_usuario'
                )
                st.plotly_chart(fig_engagement, use_container_width=True)
                
                st.metric(
                    "Promedio mensajes por usuario registrado",
                    f"{avg_messages:.1f}"
                )
            else:
                st.info("No hay datos de engagement")
    
    def _render_users_tab(self, days):
        """Renderiza la pesta√±a de an√°lisis de usuarios"""
        st.markdown("## üë• An√°lisis de Usuarios")
        
        df_daily, df_types, df_users = self.get_conversation_stats(days)
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Top usuarios m√°s activos
            if not df_users.empty:
                fig_users = px.bar(
                    df_users.head(10),
                    x='total_mensajes',
                    y='nombre_completo',
                    orientation='h',
                    title='Top 10 Usuarios M√°s Activos'
                )
                fig_users.update_layout(
                    xaxis_title="N√∫mero de Mensajes",
                    yaxis_title="Usuario"
                )
                st.plotly_chart(fig_users, use_container_width=True)
            else:
                st.info("No hay datos de usuarios registrados")
        
        with col2:
            # Tabla de usuarios
            if not df_users.empty:
                st.markdown("### üìã Detalle de Usuarios")
                st.dataframe(
                    df_users,
                    column_config={
                        "nombre_completo": "Usuario",
                        "total_mensajes": "Mensajes"
                    },
                    hide_index=True
                )
    
    def _render_words_tab(self, days):
        """Renderiza la pesta√±a de an√°lisis de palabras"""
        st.markdown("## üîç An√°lisis de Palabras Clave")
        
        df_words = self.get_word_frequency(days, limit=30)
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            if not df_words.empty:
                # Word cloud style bar chart
                fig_words = px.bar(
                    df_words.head(20),
                    x='frecuencia',
                    y='palabra',
                    orientation='h',
                    title='Top 20 Palabras M√°s Frecuentes',
                    color='frecuencia',
                    color_continuous_scale='viridis'
                )
                fig_words.update_layout(
                    xaxis_title="Frecuencia",
                    yaxis_title="Palabra",
                    yaxis={'categoryorder': 'total ascending'}
                )
                st.plotly_chart(fig_words, use_container_width=True)
            else:
                st.info("No hay suficientes datos de conversaciones para analizar palabras")
        
        with col2:
            if not df_words.empty:
                st.markdown("### üìù Tabla de Frecuencias")
                st.dataframe(
                    df_words.head(15),
                    column_config={
                        "palabra": "Palabra",
                        "frecuencia": "Frecuencia"
                    },
                    hide_index=True
                )
                
                # Insights autom√°ticos
                st.markdown("### üí° Insights")
                top_word = df_words.iloc[0]['palabra']
                top_freq = df_words.iloc[0]['frecuencia']
                
                st.write(f"‚Ä¢ La palabra m√°s frecuente es **'{top_word}'** ({top_freq} veces)")
                st.write(f"‚Ä¢ Se analizaron {len(df_words)} palabras √∫nicas")
                
                # Categor√≠as autom√°ticas
                product_words = ['producto', 'precio', 'oferta', 'descuento', 'promoci√≥n']
                service_words = ['horario', 'atenci√≥n', 'servicio', 'ayuda', 'soporte']
                
                products_found = df_words[df_words['palabra'].isin(product_words)]
                services_found = df_words[df_words['palabra'].isin(service_words)]
                
                if not products_found.empty:
                    st.write("üõí **Consultas sobre productos detectadas**")
                
                if not services_found.empty:
                    st.write("üõ†Ô∏è **Consultas sobre servicios detectadas**")
